# DÃ©tection et prÃ©diction de la fraude dans le secteur bancaire

## 1 Introduction :  

La dÃ©tection de fraude est une problÃ©matique courante dans de nombreux domaines, notamment les banques et le secteur financier, les assurances, dans le domaine social, judiciaire, et bien d'autres encore.  Au cours des derniÃ¨res annÃ©es, les tentatives de fraude ont connu une forte recrudescence, ce qui rend la lutte contre ce phÃ©nomÃ¨ne plus importante que jamais. 
     
Afin de rÃ©aliser ces dÃ©tections, les banques se focalisent aujourdâ€™hui sur lâ€™application de techniques dâ€™intelligences artificielles. Ces algorithmes, quâ€™ils soient supervisÃ©s ou non, permettent dâ€™identifier des comportements atypiques et suspects. 
     
GrÃ¢ce aux diffÃ©rentes techniques et outils avancÃ©s de Machine Learning et/ou Deep Learning, nous pouvons dÃ©tecter rapidement mais Ã©galement anticiper les actes de fraude et prendre des mesures immÃ©diates pour limiter leur impact financier. Du coup, ceci permet aux banques dâ€™amÃ©liorer grandement leurs techniques de traitement des donnÃ©es, et indirectement de multiplier les bÃ©nÃ©fices.
    
Cependant, la difficultÃ© principale repose sur le dÃ©sÃ©quilibre des classes. Selon le rapport annuel 2019 de lâ€™OSMP (2020), les transactions bancaires frauduleuses ne reprÃ©sentent que 0.001% des transactions, alors que le montant des transactions frauduleuses reprÃ©sente 1% des montants de transactions. Les donnÃ©es dÃ©sÃ©quilibrÃ©es complexifient les analyses prÃ©dictives et posent un vÃ©ritable problÃ¨me en Machine Learning et Deep Learning.
     
Afin de rÃ©soudre ces problÃ¨mes de dÃ©sÃ©quilibre des classes, nous optons pour  des mÃ©thodes de rÃ©Ã©chantillonnage (re-sampling) qui consistent Ã  modifier la distribution des donnÃ©es avant dâ€™entraÃ®ner le modÃ¨le prÃ©dictif. Cela permet dâ€™Ã©quilibrer les donnÃ©es pour faciliter la prÃ©diction.
      
Lâ€™objectif de cette Ã©tude est donc de mettre au point un modÃ¨le performant de dÃ©tection de fraude bancaire.  
 
## 2 Analyse des donnÃ©es 
### 2.1 Description des donnÃ©es 
 
Les donnÃ©es sur lesquelles nous travaillons sont des donnÃ©es rÃ©elles. Elles sont issues dâ€™une enseigne de la grande distribution ainsi que de certains organismes bancaires (FNCI et Banque de France). Chaque ligne reprÃ©sente une transaction effectuÃ©e par chÃ¨que dans un magasin de lâ€™enseigne quelque part en France. Notre Ã©tude est basÃ©e sur jeu de donnÃ©es avec deux composantes principales : 

- La variable cible FlagImpaye : câ€™est La variable Ã  prÃ©dire. Il sâ€™agit dâ€™une variable qui ne peut prendre que deux valeurs possibles : 0 la transaction est acceptÃ©e et considÃ©rÃ©e comme "normale", 1 la transaction est refusÃ©e car considÃ©rÃ©e comme "frauduleuse". 

- Les variables explicatives : On peut retrouver par exemple montant de la transaction, date de la transactionâ€¦ 

### 2.2 Analyse synthÃ©tique :  
 
Tableau Statistiques descriptives pour les variables : voir tableau des statistiques sur Python. 
RÃ©partition de la distribution entre les deux classes de la variable cible Â« FlagImpaye Â» :  
 
  <img width="265" alt="image" src="https://user-images.githubusercontent.com/114235978/216571853-6f64e1df-88af-4b06-8e68-19269eac6fc5.png">

On remarque bien qu'il y a un dÃ©sÃ©quilibre entre les deux classes. La variable cible a plus d'observations dans la classe dâ€™acceptation de transactions. 
 
### Graphique de corrÃ©lation : 

 <img width="454" alt="image" src="https://user-images.githubusercontent.com/114235978/216572013-b89f399a-3e21-4e95-af0d-e1ef52ee142d.png">
 
### CorrÃ©lation positive : 

Dâ€™aprÃ¨s la matrice de corrÃ©lation, qui mesure le degrÃ© de relation linÃ©aire entre chaque paire de variables, on constate que les variables les plus corrÃ©lÃ©es positivement avec la variable cible "FlagImpaye" sont VÃ©rifianceCPT2, VÃ©rifianceCPT3 et VÃ©rifianceCPT1. Elles dÃ©signent respectivement le nombre de transactions effectuÃ©es par le mÃªme identifiant bancaire au cours des trois derniers jours, le nombre de transactions effectuÃ©es par le mÃªme identifiant bancaire au cours des sept derniers jours et nombre de transactions effectuÃ©es par le mÃªme identifiant bancaire au cours du mÃªme jour. Ceci est interprÃ©table comme suit : plus le nombre de transactions effectuÃ©es par le mÃªme identifiant bancaire au cours des trois derniers jours est Ã©levÃ© plus la transaction est susceptible d'Ãªtre frauduleuse.  

### CorrÃ©lation nÃ©gative :  
Les variables les moins corrÃ©lÃ©es avec la variable cible "FlagImpaye" sont ScoringFP1, ScoringFP2 et ScoringFP3. 

La relation entre ScoringFP1 et la variable cible est nÃ©gative. Plus le ScoringFP1 est Ã©levÃ© moins il y a risque de fraude.  

On aurait aimÃ© tester dâ€™autres types de corrÃ©lations mais Ã§a ne fonctionne pas en raison de la volumÃ©trie des donnÃ©es. 

## 3 MÃ©thodologie : 
### 3.1 Les algorithmes de rÃ©Ã©chantillonnages : 
 
Les donnÃ©es dÃ©sÃ©quilibrÃ©es (ou imbalanced data) sont un problÃ¨me frÃ©quemment rencontrÃ© dans les modÃ¨les de classification, quâ€™il sâ€™agisse de classification binaire ou de classification multi-classes. Dans notre cas il sâ€™agit dâ€™une classification binaire (acceptation ou refus de transaction). 
On peut parler de donnÃ©es dÃ©sÃ©quilibrÃ©es dÃ¨s lors que les deux classes ne sont pas prÃ©sentes avec la mÃªme frÃ©quence dans les donnÃ©es, i.e. que le ratio nâ€™est pas 50%/50%. Mais en pratique on ne parle de donnÃ©es dÃ©sÃ©quilibrÃ©es quâ€™Ã  partir du moment oÃ¹ le dÃ©sÃ©quilibre dÃ©passe 10%/90%.  

Dans ce cas de dÃ©tection de fraude, on remarque que 99.12% des transactions effectuÃ©es sont valides, et seulement 0.88% frauduleuses. Les transactions valides sont alors appelÃ©es la classe majoritaire, et les fraudes la classe minoritaire. 

Ceci pose de rÃ©elles difficultÃ©s aux algorithmes de Machine Learning et de Deep Learning et conduit surtout au sur apprentissage. 
Lâ€™une des solutions pour traiter les donnÃ©es dÃ©sÃ©quilibrÃ©es est de les â€œrÃ©Ã©quilibrerâ€. Ce type dâ€™approches â€“ appelÃ©es data-level solutions â€“ se dÃ©cline sous 2 formes principales : 

- Le sur-Ã©chantillonnage (oversampling) : Le nombre dâ€™individus minoritaires est augmentÃ© pour quâ€™ils aient plus dâ€™importance lors de la modÃ©lisation. DiffÃ©rentes solutions sont possibles, comme le SMOTE, Adasyn, Random, etc. Pour notre cas, on a optÃ© pour le SMOTE qui consiste Ã  synthÃ©tiser des Ã©lÃ©ments de la classe minoritaire, sur la base de ceux qui existent dÃ©jÃ . Il sÃ©lectionne alÃ©atoirement un point de la classe minoritaire et calcul les k-voisins les plus proches pour ce point. Les points synthÃ©tiques sont ajoutÃ©s entre le point choisi et ses voisins. 
  
- Le sous-Ã©chantillonnage (undersampling) : Parmi les individus majoritaires, on en retire une partie afin dâ€™accorder plus dâ€™importance aux individus minoritaires. Cette approche permet de diminuer la redondance des informations apportÃ©es par le grand nombre dâ€™individus majoritaires. Pour notre cas, on a optÃ© pour le Random Under Sampler. 
 
### 3.2 Algorithmes de prÃ©diction utilisÃ©e : 
- Random Forest

- ModÃ¨le NN : Perceptron multicouche 

- XGBoost

### 3.3 Mesures de performance : 

Une autre solution pour amÃ©liorer les performances des algorithmes sur des jeux de donnÃ©es dÃ©sÃ©quilibrÃ©s est de travailler sur la mÃ©trique de validation. Pour la dÃ©tection de fraude, plutÃ´t que dâ€™utiliser lâ€™accuracy, nous utiliserons le F1-score pour Ã©valuer la performance des diffÃ©rents algorithmes et techniques de classification utilisÃ©es dans notre dÃ©marche.

Dans ce cas, il est plus intÃ©ressant que lâ€™accuracy car le nombre de vrais nÃ©gatifs (TN) nâ€™est pas pris en compte. Et dans les situations dâ€™imbalanced class, nous avons une majoritÃ© de vrais nÃ©gatifs qui faussent complÃ¨tement notre perception de la performance de lâ€™algorithme. Un grand nombre de vrais nÃ©gatifs (TN) laissera le F1-Score de marbre. 

Le F1-score permet de rÃ©sumer les valeurs de la precision et du recall en une seule mÃ©trique. MathÃ©matiquement, le F1-score est dÃ©fini comme Ã©tant la moyenne harmonique de la precision et du recall, ce qui se traduit par lâ€™Ã©quation suivante : 

ğ¹1-ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ = 2 x (Precision Ã— Rappel)/(Precision + Rappel)

Avec la PrÃ©cision dÃ©finit comme TN/(TN+FN) et le rappel comme  TN/(TN+FP)

Et la matrice de confusion est dÃ©finie somme suit :

<img width="514" alt="Capture dâ€™eÌcran 2023-02-03 aÌ€ 11 10 50" src="https://user-images.githubusercontent.com/114235978/216573335-d20be5a3-523e-4250-a907-96c842b476f8.png">

Dans notre cas on cherche Ã  minimiser le taux dâ€™erreur sur la classe positive (FP) et Ã  maximiser le F1-score, lâ€™enjeu est de trouver un compromis entre les deux. 

ğ‘‡ğ‘ğ‘¢ğ‘¥ dâ€™erreur ğ‘ ğ‘¢ğ‘Ÿ ğ‘™ğ‘ ğ‘ğ‘™ğ‘ğ‘ ğ‘ ğ‘’ ğ‘ğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’ = FP/(FP+TP)

Ce qui nous intÃ©resse dans ce cas câ€™est le fait de prÃ©dire les fraudes (les cas positifs) câ€™est pour cette raison quâ€™on sâ€™intÃ©resse Ã  la mesure du taux dâ€™erreur de la classe positive.  

## 4 ExpÃ©riences : 

Avant dâ€™analyser les donnÃ©es et dâ€™entraÃ®ner les modÃ¨les, il convient de retraiter les donnÃ©es pour quâ€™elles soient comprÃ©hensibles par lâ€™API de scikit-learn. 

- On a supprimÃ© la variable "CodeDecision" car cette information est acquise post-transaction, et la variable "ZINBIN" qui est lâ€™identifiant des clients. Donc on a gardÃ© 21 variables dans le modÃ¨le au final.

- On a supprimÃ© les lignes dupliquÃ©es.

- On a remplacÃ© les virgules par un espace. 

- On a transformÃ© toutes les variables catÃ©gorielles en numÃ©riques (float).

- On a extrait la colonne date pour pouvoir partitionner en apprentissage et test:

	- Apprentissage : transactions ayant eu lieu entre le "2017-02-01" et le "2017- 08-31". 
  
	- Test : transactions ayant eu lieu entre le "2017-09-01" et le "2017-11-30".

### 4.1 Les diffÃ©rents algorithmes testÃ©s sous H20

- H2ORandomForestEstimator. 

- H2ODeepLearningEstimator.  

- AutoML 
GrÃ¢ce au modÃ¨le AutoML, on a obtenu le meilleur modÃ¨le XGBOOST et pour la suite on a cherchÃ© Ã  optimiser les paramÃ¨tres pour ce modÃ¨le. 

- XGBoost  
Le dernier modÃ¨le que nous avons testÃ© est le XGBoost. Sous H2O, nous utilisons la classe H2OXGBoostEstimator et les hyper-paramÃ¨tres de lâ€™algorithme (max_depth et ntrees) sont optimisÃ©s par GridSearchCV. On rÃ©cupÃ¨re le meilleur modÃ¨le avec les meilleurs paramÃ¨tres et on effectue la prÃ©diction sur les donnÃ©es test. 

### 4.2 RÃ©sultats :  

<img width="820" alt="Capture dâ€™eÌcran 2023-02-03 aÌ€ 11 16 34" src="https://user-images.githubusercontent.com/114235978/216574677-ff236582-c94a-45e3-9649-07159265790c.png">
 
Pour le dÃ©ploiement, on enregistre le modÃ¨le quâ€™il a le F1_score Ã©levÃ©e et le taux d'erreur sur la classe positive moins Ã©levÃ©, c'est le modÃ¨le XGBoost avec les paramÃ¨tres optimaux (ntrees, max_depth) = (50,10) (f1_score = 0.846, le taux d'erreur sur la classe positive = 0.089).

## 5 Conclusion :  

Cette Ã©tude avait pour objectif de dÃ©terminer, quels sont les algorithmes de classification les plus efficaces pour prÃ©dire la prÃ©sence/absence des transactions frauduleuses en fonction des caractÃ©ristiques des transactions.

Au moyen des diffÃ©rentes mesures de performances de classification et des diffÃ©rents algorithmes mis en place pour lâ€™ensemble de donnÃ©es, lâ€™algorithme XGBoost avec lâ€™optimisation de ses paramÃ¨tres avec la mÃ©thode GRIDSERACHCV apparait le plus performant pour prÃ©dire la dÃ©tection ou non des fraudes pour le jeu de donnÃ©es avec les techniques de rÃ©Ã©chantillonnages comme prÃ©traitement utilisÃ©. Nous avons donc sÃ©lectionnÃ© et dÃ©ployÃ© ce modÃ¨le nommÃ© Â« Grid_XGBoost_model Â».
